{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction  of Dos attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names\n",
    "features = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"Wrong_fragment\", \"Urgent\", \"hot\", \"num_failed_login\", \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_ srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host _rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\"class\"] \n",
    "data = p.read_csv(\"data6.csv\", names = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DOS'] = df['class'].map({'normal.':0, 'snmpgetattack.':0, 'named.':0, 'xlock.':0, 'smurf.':1,\n",
    "       'ipsweep.':0, 'multihop.':0, 'xsnoop.':0, 'sendmail.':0, 'guess_passwd.':0,\n",
    "       'saint.':0, 'buffer_overflow.':0, 'portsweep.':0, 'pod.':1, 'apache2.':1,\n",
    "       'phf.':0, 'udpstorm.':1, 'warezmaster.':0, 'perl.':0, 'satan.':0, 'xterm.':0,\n",
    "       'mscan.':0, 'processtable.':1, 'ps.':0, 'nmap.':0, 'rootkit.':0, 'neptune.':1,\n",
    "       'loadmodule.':0, 'imap.':0, 'back.':1, 'httptunnel.':0, 'worm.':0,\n",
    "       'mailbomb.':1, 'ftp_write.':0, 'teardrop.':1, 'land.':1, 'sqlattack.':0,\n",
    "       'snmpguess.':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "       'dst_bytes', 'land', 'Wrong_fragment', 'Urgent', 'hot',\n",
    "       'num_failed_login', 'logged_in', 'num_compromised', 'root_shell',\n",
    "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "       'dst_host_diff_ srv_rate', 'dst_host_same_src_port_rate',\n",
    "       'dst_host_srv_diff_host _rate', 'dst_host_serror_rate',\n",
    "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate'\n",
    "       ]\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del df['dst_host_srv_rerror_rate']\n",
    "\n",
    "del df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='DOS', axis=1)\n",
    "#Response variable\n",
    "y = df.loc[:,'DOS']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " #We'll use a test size of 30%. We also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Logistic Regression Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87       454\n",
      "           1       0.74      0.20      0.31       146\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.77      0.59      0.59       600\n",
      "weighted avg       0.78      0.79      0.74       600\n",
      "\n",
      "Confusion Matrix result of Logistic Regression is:\n",
      " [[444  10]\n",
      " [117  29]]\n",
      "\n",
      "Sensitivity :  0.9779735682819384\n",
      "\n",
      "Specificity :  0.19863013698630136\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[0.77333333 0.77666667 0.79333333 0.80333333 0.78333333 0.81\n",
      " 0.80333333 0.78333333 0.79       0.78666667]\n",
      "\n",
      "Accuracy result of Logistic Regression is: 79.03333333333332\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logR= LogisticRegression()\n",
    "logR.fit(X_train,y_train)\n",
    "predictR = logR.predict(X_test)\n",
    "print(\"\")\n",
    "print('Classification report of Logistic Regression Results:')\n",
    "print(\"\")\n",
    "print(classification_report(y_test,predictR))\n",
    "\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Logistic Regression is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n",
    "\n",
    "accuracy = cross_val_score(logR, X, y, cv=10, scoring='accuracy')\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of Logistic Regression is:\",accuracy.mean() * 100)\n",
    "lr=accuracy.mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Decision Tree Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.86       454\n",
      "           1       0.60      0.20      0.30       146\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.70      0.58      0.58       600\n",
      "weighted avg       0.74      0.77      0.73       600\n",
      "\n",
      "Confusion Matrix result of Decision Tree is:\n",
      " [[435  19]\n",
      " [117  29]]\n",
      "\n",
      "Sensitivity :  0.9581497797356828\n",
      "\n",
      "Specificity :  0.19863013698630136\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[0.79       0.78       0.77666667 0.78333333 0.79666667 0.8\n",
      " 0.79333333 0.76333333 0.78       0.79      ]\n",
      "\n",
      "Accuracy result of Decision Tree is: 78.53333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt= DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "predictR = dt.predict(X_test)\n",
    "print(\"\")\n",
    "print('Classification report of Decision Tree Results:')\n",
    "print(\"\")\n",
    "print(classification_report(y_test,predictR))\n",
    "\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Decision Tree is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n",
    "\n",
    "accuracy = cross_val_score(dt, X, y, cv=10, scoring='accuracy')\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of Decision Tree is:\",accuracy.mean() * 100)\n",
    "dt=accuracy.mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Random Forest Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       454\n",
      "           1       0.66      0.21      0.32       146\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.73      0.59      0.60       600\n",
      "weighted avg       0.76      0.78      0.74       600\n",
      "\n",
      "\n",
      "Confusion Matrix result of Random Forest is:\n",
      " [[438  16]\n",
      " [115  31]]\n",
      "\n",
      "Sensitivity :  0.9647577092511013\n",
      "\n",
      "Specificity :  0.21232876712328766\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[0.78333333 0.78       0.77333333 0.79666667 0.78       0.79666667\n",
      " 0.79333333 0.77666667 0.79666667 0.78666667]\n",
      "\n",
      "Accuracy result of Random Forest is: 78.63333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "predictR = rfc.predict(X_test)\n",
    "print(\"\")\n",
    "print('Classification report of Random Forest Results:')\n",
    "print(\"\")\n",
    "print(classification_report(y_test,predictR))\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Random Forest is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n",
    "\n",
    "accuracy = cross_val_score(rfc, X, y, cv=10, scoring='accuracy')\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of Random Forest is:\",accuracy.mean() * 100)\n",
    "rf=accuracy.mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Support Vector Classifier Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87       454\n",
      "           1       0.74      0.19      0.30       146\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.58      0.59       600\n",
      "weighted avg       0.78      0.79      0.74       600\n",
      "\n",
      "\n",
      "Confusion Matrix result of Support Vector Classifier is:\n",
      " [[444  10]\n",
      " [118  28]]\n",
      "\n",
      "Sensitivity :  0.9779735682819384\n",
      "\n",
      "Specificity :  0.1917808219178082\n",
      "Cross validation test results of accuracy:\n",
      "[0.77       0.77333333 0.79333333 0.8        0.78666667 0.80666667\n",
      " 0.80333333 0.77666667 0.77666667 0.78      ]\n",
      "\n",
      "Accuracy result of Support Vector Classifier is: 78.66666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv = SVC()\n",
    "sv.fit(X_train, y_train)\n",
    "predictSVC = sv.predict(X_test)\n",
    "print(\"\")\n",
    "print('Classification report of Support Vector Classifier Results:')\n",
    "print(\"\")\n",
    "print(classification_report(y_test,predictSVC))\n",
    "\n",
    "print(\"\")\n",
    "cm4=confusion_matrix(y_test,predictSVC)\n",
    "print('Confusion Matrix result of Support Vector Classifier is:\\n', confusion_matrix(y_test,predictSVC))\n",
    "print(\"\")\n",
    "sensitivity1 = cm4[0,0]/(cm4[0,0]+cm4[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm4[1,1]/(cm4[1,0]+cm4[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "accuracy = cross_val_score(sv, X, y,cv=10,  scoring='accuracy')\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of Support Vector Classifier is:\",accuracy.mean() * 100)\n",
    "sv=accuracy.mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Naive Bayes Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86       454\n",
      "           1       0.62      0.09      0.16       146\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.69      0.54      0.51       600\n",
      "weighted avg       0.73      0.77      0.69       600\n",
      "\n",
      "\n",
      "Confusion Matrix result of Naive Bayes is:\n",
      " [[446   8]\n",
      " [133  13]]\n",
      "\n",
      "Sensitivity :  0.9823788546255506\n",
      "\n",
      "Specificity :  0.08904109589041095\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[0.76666667 0.78       0.77333333 0.77       0.75666667 0.76666667\n",
      " 0.78333333 0.76333333 0.77666667 0.77666667]\n",
      "\n",
      "Accuracy result of  Naive Bayes is: 77.13333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "predictR = gnb.predict(X_test)\n",
    "print(\"\")\n",
    "print('Classification report of Naive Bayes Results:')\n",
    "print(\"\")\n",
    "print(classification_report(y_test,predictR))\n",
    "\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Naive Bayes is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n",
    "\n",
    "accuracy = cross_val_score(gnb, X, y, cv=10, scoring='accuracy')\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of  Naive Bayes is:\",accuracy.mean() * 100)\n",
    "nb=accuracy.mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of K-Nearest Neighbor Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86       454\n",
      "           1       0.61      0.15      0.24       146\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.70      0.56      0.55       600\n",
      "weighted avg       0.74      0.77      0.71       600\n",
      "\n",
      "\n",
      "Confusion Matrix result of K-Nearest Neighbor is:\n",
      " [[440  14]\n",
      " [124  22]]\n",
      "\n",
      "Sensitivity :  0.9691629955947136\n",
      "\n",
      "Specificity :  0.1506849315068493\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[0.76       0.77333333 0.39       0.79666667 0.78       0.79\n",
      " 0.79333333 0.76666667 0.77       0.78666667]\n",
      "\n",
      "Accuracy result of  K-Nearest Neighbor is: 74.06666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnc = KNeighborsClassifier()\n",
    "knnc.fit(X_train,y_train)\n",
    "predictR = knnc.predict(X_test)\n",
    "print(\"\")\n",
    "print('Classification report of K-Nearest Neighbor Results:')\n",
    "print(\"\")\n",
    "print(classification_report(y_test,predictR))\n",
    "\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of K-Nearest Neighbor is:\\n',cm2)\n",
    "print(\"\")\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n",
    "\n",
    "accuracy = cross_val_score(knnc, X, y, cv=10, scoring='accuracy')\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of  K-Nearest Neighbor is:\",accuracy.mean() * 100)\n",
    "kn=accuracy.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph():\n",
    "    import matplotlib.pyplot as plt\n",
    "    data=[lr,dt,rf,sv,nb,kn]\n",
    "    alg=\"LR\",\"DT\",\"RF\",\"SVM\",\"NB\",\"KNN\"\n",
    "    plt.figure(figsize=(10,5))\n",
    "    b=plt.bar(alg,data,color=(\"r\",\"g\",\"b\",\"y\",\"m\",\"black\"))\n",
    "    plt.title(\"Accuracy comparison of DoS Attacks\",fontsize=15)\n",
    "    plt.legend(b,data,fontsize=9)\n",
    "    plt.savefig('DOS.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tkinter\n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, NavigationToolbar2Tk)\n",
    "from matplotlib.backend_bases import key_press_handler\n",
    "from matplotlib.figure import Figure\n",
    "import numpy as np\n",
    "root = tkinter.Tk()\n",
    "root.wm_title(\"Accuracy plot for DoS Attacks\")\n",
    "fig = Figure(figsize=(10,10),dpi=1)\n",
    "canvas = FigureCanvasTkAgg(fig, master=root)  \n",
    "canvas.draw()\n",
    "canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "icon=tkinter.PhotoImage(file='DOS.png')   \n",
    "label=tkinter.Label(root,image=icon)\n",
    "label.pack()\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
